#include "OpenVINOEngine.hpp"
#include <inference_engine.hpp>
#include <FAST/Utility.hpp>

namespace fast {

using namespace InferenceEngine;

void OpenVINOEngine::run() {
    // --------------------------- 6. Prepare input --------------------------------------------------------
    auto inputTensor = mInputNodes.begin()->second.data;
    auto access = inputTensor->getAccess(ACCESS_READ);
    auto data = access->getData<4>();
    Blob::Ptr input = m_inferRequest->GetBlob(mInputNodes.begin()->first);
    auto input_data = input->buffer().as<PrecisionTrait<Precision::FP32>::value_type *>();
    std::memcpy(input_data, data.data(), input->byteSize());

    reportInfo() << "OpenVINO: Ready to execute." << reportEnd();
    m_inferRequest->Infer();
    reportInfo() << "OpenVINO: Network executed." << reportEnd();
    // --------------------------- 8. Process output ------------------------------------------------------
    Blob::Ptr output = m_inferRequest->GetBlob(mOutputNodes.begin()->first);
    auto outputData = (output->buffer().as<::InferenceEngine::PrecisionTrait<Precision::FP32>::value_type*>());
    auto copied_data = make_uninitialized_unique<float[]>(output->byteSize());
    std::memcpy(copied_data.get(), outputData, output->byteSize());
    auto tensor = Tensor::New();
    tensor->create(std::move(copied_data), mOutputNodes.begin()->second.shape);
    mOutputNodes.begin()->second.data = tensor;
}

void OpenVINOEngine::load() {
    PluginDispatcher dispatcher({"/opt/intel/computer_vision_sdk/inference_engine/lib/ubuntu_16.04/intel64/", ""});
    InferencePlugin plugin(dispatcher.getSuitablePlugin(TargetDevice::eCPU));
    reportInfo() << "OpenVINO: Inference plugin setup complete." << reportEnd();

    // --------------------------- 2. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
    CNNNetReader network_reader;
    auto input_model = getFilename();
    network_reader.ReadNetwork(fileNameToString(input_model));
    network_reader.ReadWeights(fileNameToString(input_model).substr(0, input_model.size() - 4) + ".bin");
    CNNNetwork network = network_reader.getNetwork();
    //network.setBatchSize(1);
    reportInfo() << "OpenVINO: Network loaded." << reportEnd();
    // -----------------------------------------------------------------------------------------------------

    // --------------------------- 3. Configure input & output ---------------------------------------------
    // --------------------------- Prepare input blobs -----------------------------------------------------
    InputInfo::Ptr input_info = network.getInputsInfo().begin()->second;
    std::string input_name = network.getInputsInfo().begin()->first;
    input_info->setLayout(Layout::NCHW);
    input_info->setPrecision(Precision::FP32);
    TensorShape shape;
    for(auto dim : input_info->getDims())
        shape.addDimension(dim);
    addInputNode(0, input_name, NodeType::IMAGE, TensorShape({1, 1, 256, 256}));
    reportInfo() << "Input node is: " << input_name << " with shape " << shape.toString() << reportEnd();


    // --------------------------- Prepare output blobs ----------------------------------------------------
    DataPtr output_info = network.getOutputsInfo().begin()->second;
    std::string output_name = network.getOutputsInfo().begin()->first;
    TensorShape outputShape;
    for(auto dim : output_info->getDims())
        outputShape.addDimension(dim);
    addOutputNode(0, output_name, NodeType::TENSOR, outputShape);
    reportInfo() << "Output node is: " << output_name << " with shape " << outputShape.toString() << reportEnd();

    output_info->setPrecision(Precision::FP32);
    reportInfo() << "OpenVINO: Node setup complete." << reportEnd();

    ExecutableNetwork executable_network = plugin.LoadNetwork(network, {});

    m_inferRequest = executable_network.CreateInferRequestPtr();
    setIsLoaded(true);
    reportInfo() << "OpenVINO: Network fully loaded." << reportEnd();
}

ImageOrdering OpenVINOEngine::getPreferredImageOrdering() const {
    return ImageOrdering::CHW;
}

std::string OpenVINOEngine::getName() const {
    return "OpenVINO";
}
}
